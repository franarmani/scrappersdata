name: Scraper AutomÃ¡tico

on:
  schedule:
    # Ejecutar cada 30 minutos
    - cron: '*/30 * * * *'
  workflow_dispatch: # Permitir ejecuciÃ³n manual

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout cÃ³digo
      uses: actions/checkout@v4
      
    - name: Configurar Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 python-dotenv
        pip install supabase 2>/dev/null || true
        
    - name: Ejecutar scraper
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        python scraper_integrado.py --auto
        
    - name: Commit y Push de partidos.json
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add public/partidos.json
        git diff --quiet && git diff --staged --quiet || (git commit -m "ðŸ¤– Actualizar partidos.json - $(date '+%Y-%m-%d %H:%M')" && git push)
