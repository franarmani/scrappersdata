# Scraper de PelÃ­culas con SincronizaciÃ³n AutomÃ¡tica

## ğŸ¬ DescripciÃ³n

Scraper automÃ¡tico de pelÃ­culas desde **verpeliculasultra.com** con sincronizaciÃ³n integrada a **GitHub** y **Supabase**.

### CaracterÃ­sticas

âœ… **ExtracciÃ³n de datos:**
- TÃ­tulos y aÃ±os de pelÃ­culas
- BÃºsqueda automÃ¡tica de IDs en TMDB
- ExtracciÃ³n de servidores con URLs completas
- InformaciÃ³n de idiomas disponibles

âœ… **SincronizaciÃ³n automÃ¡tica:**
- Push automÃ¡tico a GitHub despuÃ©s de cada scraping
- SincronizaciÃ³n de datos a Supabase
- Manejo de cambios remotos (rebase)
- Logging detallado de cada paso

âœ… **Estructura de datos unificada:**
```json
{
  "tmdb_id": 1054867,
  "title": "Una batalla tras otra",
  "year": "2025",
  "servers": [
    {
      "url": "https://hglink.to/e/...",
      "server": "hglink.to",
      "language": "EspaÃ±ol"
    }
  ]
}
```

## ğŸ“‹ Requisitos

### InstalaciÃ³n de dependencias

```bash
pip install -r requirements.txt
```

**Dependencias principales:**
- `requests` - Solicitudes HTTP
- `beautifulsoup4` - Parsing HTML
- `undetected-chromedriver` - NavegaciÃ³n web sin detecciÃ³n
- `selenium` - AutomatizaciÃ³n web
- `python-dotenv` - Variables de entorno
- `supabase` - Cliente de Supabase

### Variables de entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anonymous-key
```

### ConfiguraciÃ³n de Git

Asegurarse de que Git estÃ© configurado:

```bash
git config --global user.name "Tu Nombre"
git config --global user.email "tu@email.com"
```

## ğŸš€ Uso

### EjecuciÃ³n bÃ¡sica (1 pÃ¡gina)

```bash
python scraper_pelisplushd_movies.py
```

### Scraping de mÃºltiples pÃ¡ginas

```bash
python scraper_pelisplushd_movies.py --max-pages 5
```

### Especificar archivo de salida

```bash
python scraper_pelisplushd_movies.py --max-pages 3 --output custom_path/peliculas.json
```

### Prueba rÃ¡pida

```bash
python test_scraper_auto.py
```

## ğŸ“Š Flujo de ejecuciÃ³n

1. **ExtracciÃ³n** â†’ Scraping de datos desde verpeliculasultra.com
2. **Enriquecimiento** â†’ BÃºsqueda de metadatos en TMDB
3. **Guardado** â†’ Almacenamiento en JSON local
4. **GitHub** â†’ Commit y push automÃ¡tico
5. **Supabase** â†’ SincronizaciÃ³n de base de datos

## ğŸ“ Logs y Monitoreo

El script genera logs detallados:

```
2026-02-04 16:30:15 - INFO - Iniciando scraper de verpeliculasultra.com...
2026-02-04 16:30:18 - INFO - Se encontraron 24 pelÃ­culas en la pÃ¡gina
2026-02-04 16:30:45 - INFO - âœ… Guardadas 47 pelÃ­culas en .../peliculas.json
2026-02-04 16:30:47 - INFO - ğŸš€ SINCRONIZANDO CON GITHUB
2026-02-04 16:30:52 - INFO - ğŸ‰ Â¡Push a GitHub exitoso!
2026-02-04 16:30:55 - INFO - ğŸš€ SINCRONIZANDO CON SUPABASE
2026-02-04 16:31:20 - INFO - ğŸ‰ Â¡PelÃ­culas sincronizadas con Supabase exitosamente!
```

## âš ï¸ Manejo de errores

El scraper es robusto frente a errores comunes:

- **Sin conexiÃ³n a GitHub:** Guarda el JSON y avisa de forma amigable
- **Sin acceso a Supabase:** ContinÃºa con el guardado local
- **PelÃ­cula no encontrada en TMDB:** La omite y continÃºa
- **Servidor sin respuesta:** Reintentos automÃ¡ticos con timeout

## ğŸ“¦ Estructura de archivos

```
peliculas/
â”œâ”€â”€ scraper_pelisplushd_movies.py    # Scraper principal
â”œâ”€â”€ sync_movies_supabase.py          # MÃ³dulo Supabase
â”œâ”€â”€ test_scraper_auto.py             # Script de prueba
â”œâ”€â”€ SCRAPER_PELICULAS_README.md      # Este archivo
â””â”€â”€ scrappersdata/
    â””â”€â”€ peliculas.json               # Base de datos local
```

## ğŸ”§ PersonalizaciÃ³n

### Modificar pÃ¡ginas a extraer

En `scraper_pelisplushd_movies.py`, lÃ­nea ~300:

```python
parser.add_argument('--max-pages', type=int, default=1, help='NÃºmero mÃ¡ximo de pÃ¡ginas a scrapear')
```

### Cambiar tabla Supabase

En `sync_movies_supabase.py`, lÃ­nea ~14:

```python
self.table_name = 'tu_tabla_aqui'  # Cambiar nombre de tabla
```

### Filtrar por idioma

Agregar en `extraer_servidores()`:

```python
if idioma == 'EspaÃ±ol':  # Filtrar solo espaÃ±ol
    servidores.append(servidor_info)
```

## ğŸ› SoluciÃ³n de problemas

### Error: "pathspec did not match any files"

```bash
git add .
git status
```

### Error: "untracked working tree files would be overwritten"

```bash
git clean -fd
git pull origin master
```

### Supabase connection refused

- Verificar variables de entorno: `echo $SUPABASE_URL`
- Verificar conexiÃ³n a internet
- Verificar credenciales en Supabase Dashboard

### TMDB API errors

- Verificar que `TMDB_API_KEY` es vÃ¡lida
- Verificar lÃ­mite de requests (2500/day)
- Esperar 1 segundo entre requests (ya configurado)

## ğŸ“ˆ EstadÃ­sticas y mÃ©tricas

DespuÃ©s de cada ejecuciÃ³n:

```
âœ… Scraping completado. Total: 47 pelÃ­culas
  â• Insertadas: 23
  âœï¸ Actualizadas: 24
  âŒ Errores: 0
```

## ğŸ”„ AutomatizaciÃ³n (Windows)

Crear `run_scraper_auto.bat`:

```batch
@echo off
cd /d "C:\Users\franc\Desktop\SCRAPPERS\PELICULAS-SERIES-ANIME\peliculas"
python scraper_pelisplushd_movies.py --max-pages 5
pause
```

Programar con Task Scheduler para ejecuciÃ³n automÃ¡tica diaria.

## ğŸ“š Recursos

- **TMDB API:** https://www.themoviedb.org/settings/api
- **Supabase Docs:** https://supabase.com/docs
- **Git Documentation:** https://git-scm.com/doc
- **BeautifulSoup:** https://www.crummy.com/software/BeautifulSoup/

## ğŸ“ Soporte

Para problemas o mejoras:

1. Verificar logs detallados
2. Revisar archivo `.env`
3. Comprobar conexiones de red
4. Consultar documentaciÃ³n oficial de dependencias

## ğŸ“„ Licencia

Uso personal - Proyecto de scraping web

---

**Ãšltima actualizaciÃ³n:** 4 de febrero, 2026
